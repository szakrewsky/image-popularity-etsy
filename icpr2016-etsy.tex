
\documentclass[conference,a4paper]{IEEEtran}

\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{supertabular}
\usepackage{graphicx,subfigure}
\usepackage{multirow}
\usepackage[bottom]{footmisc}
\usepackage{url}
\usepackage{color}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{authblk}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{epsfig}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{graphicx,subfigure}
\usepackage{url}
\usepackage{subfloat}
\usepackage{times}
\usepackage{balance}
\usepackage[dvipsnames]{xcolor}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage[
top    = 0.75 in,
bottom = 2in,
left   = 1in,
right  = 1in]{geometry}

% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found as epslatex.ps or
% epslatex.pdf at: http://www.ctan.org/tex-archive/info/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex


\newcommand{\kamelia}[1]{{\color{blue}{#1}}}
\newcommand{\steve}[3]{{\colod{green}}}
\newcommand{\ali}[2]{{\color{red}{#1~}}}

\newcommand{\etc}{etc.~}
\newcommand{\etal}{et al.~}
\newcommand{\footlabel}[2]{%
    \addtocounter{footnote}{1}%
    \footnotetext[\thefootnote]{%
        \addtocounter{footnote}{-1}%
        \refstepcounter{footnote}\label{#1}%
        #2%
    }%
    $^{\ref{#1}}$%
}

\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
%some lame title for now
\title{Handcrafted Goods to Handcrafted Image Features: Image Popularity on Etsy}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations

 \author{
Stephen Zakrewsky\\
\emph{Drexel University}\\
\emph{sz372@drexel.edu}
\and
Kamelia Aryafar\\ 
\emph {Etsy Inc.}\\
\emph {karyafar@etsy.com}
\and
Ali Shokoufandeh\\
\emph{Drexel University}\\
\emph{ashokouf@cs.drexel.edu}}



% make the title area
\maketitle

\begin{abstract}
%\boldmath
Online retail is a visual experience- Shoppers often use images as the first
 order information to decide if an item matches their taste. 
 Image characteristics such as color, scene composition, texture, style, 
 aesthetics and overall quality play a crucial role in
  making a purchase decision, clicking on or liking a product listing. 

In this paper we use a set of image features that indicate quality
   to predict product listings popularity on a major e-commerce website, Etsy~\footlabel{etsyurl}{\url{www.etsy.com}}.
   We first define listing popularity on Etsy through search clicks, favoriting and purchase activity. Next, we infer listing quality from the pixel-level information of listed images on Etsy as quality features. We then compare our findings to text-only models for popularity prediction. Our initial results indicate that a combined image and text modeling of product listings on Etsy outperforms text-only models in popularity prediction.
\end{abstract}
% IEEEtran.cls defaults to using nonbold math in the Abstract.
% This preserves the distinction between vectors and scalars. However,
% if the conference you are submitting to favors bold math in the abstract,
% then you can use LaTeX's standard command \boldmath at the very start
% of the abstract to achieve this. Many IEEE journals/conferences frown on
% math in the abstract anyway.

% no keywords




% For peer review papers, you can put extra information on the cover
% page as needed:
\ifCLASSOPTIONpeerreview
 \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
 \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
The informative presentation of product listings through text and 
images is the foundation of e-commerce websites. Shoppers often have a 
specific style or visual preference for many of the available items such as jewelry, clothing, home decor and etc. 
Images provide the first order information for product listings. 
Users usually use images in combination with textual description, price, ratings and \etc to decide if an item is a suitable match for what they need and have in mind. The selection of proper high quality images is then an important step in listing a successful product. In this paper we examine the role of image quality in a listing popularity on a major e-commerce website, Etsy~\footref{etsyurl}.



Etsy is an online marketplace for artisans selling unique handcrafted goods, and vintage wares that
couldn't be found elsewhere. Etsy caters to the long tail of online retail~\cite{Anderson:2006,aryafar2014exploring}. With more than one million sellers, nearly $35$ million unique product listings and nearly a hundred million images, Etsy is uniquely positioned to answer some inetersting questions about the role of images as a rich visual experience in an e-commerce setting. Each Etsy listing is composed of text information such as title, tags, item description, shop and seller name and complementary images. For a product listing to stand out, high-quality images describing the content of the product listing is a necessity~\cite{wang2011aesthetics,obrador2009role}. 


\begin{figure}
  \centering
    \includegraphics[scale=0.15]{./figures/sample1.jpg}
    \includegraphics[scale=0.15]{./figures/sample2.jpg}
     \includegraphics[scale=0.15]{./figures/sample3.jpg}
    \includegraphics[scale=0.15]{./figures/sample4.jpg}
    \includegraphics[scale=0.15]{./figures/sample17.jpg}
    \includegraphics[scale=0.15]{./figures/sample18.jpg}
     \includegraphics[scale=0.15]{./figures/sample19.jpg}
    \includegraphics[scale=0.15]{./figures/sample20.jpg}
     \includegraphics[scale=0.15]{./figures/sample5.jpg}
    \includegraphics[scale=0.15]{./figures/sample6.jpg}
     \includegraphics[scale=0.15]{./figures/sample7.jpg}
    \includegraphics[scale=0.15]{./figures/sample8.jpg}
     \includegraphics[scale=0.15]{./figures/sample9.jpg}
     \includegraphics[scale=0.15]{./figures/sample10.jpg}
    \includegraphics[scale=0.15]{./figures/sample11.jpg}
     \includegraphics[scale=0.15]{./figures/sample12.jpg}
       \includegraphics[scale=0.15]{./figures/sample13.jpg}
     \includegraphics[scale=0.15]{./figures/sample14.jpg}
    \includegraphics[scale=0.15]{./figures/sample15.jpg}
     \includegraphics[scale=0.15]{./figures/sample16.jpg}
  \caption{
  Sample Etsy listing images are shown with different lighting, scene composition, and quality.
  }
  \label{fig:etsylistings}
\end{figure}


In this paper we introduce a mechanism for extracting popularity of product listings from the images representing those listings. We then explore the correlation between listings' popularity and user interaction with what is for sale. Because sales are rare in comparison to the number of items available on a large site such as Etsy, we look into an alternative mechanism for interaction, the ``favorite.'' Favorites on Etsy are similar to any number of ``like'' mechanisms available online, the most familiar of which is Facebook's ubiquitous ``thumbs-up.'' By considering what users explicitly express interest in, we are able to form relationships between user preferences and popularity-based image features. 
 
The remainder of the paper is organized as follows:
Section~\ref{sec:background} discusses background on predicting image popularity.
Section~\ref{sec:features} describes the features we used to predict populartiy.  We examine the
performance of popularity features in predicting favorite listings classification in
section~\ref{sec:classification} and explore the popularity entropy among active users in
section~\ref{sec:entropy}. Finally, we conclude this paper in
section~\ref{sec:conclusion} and propose future research directions.
%JOSH

\section{Background}
\label{sec:background}
Early work in the literature has defined popularity as quality~\cite{ke2006design} or aesthetics~\cite{datta2006studying} and use data from photography rating websites where users who have interest in photography upload their photos and rate others.  Popularity has also been defined as memorability~\cite{isola2011makes}, and interestingness~\cite{dhar2011high,gygli2013interestingness}.  More recent work has directly tackled popularity.  In \cite{khosla2014makes}, popularity is defined as the number of views on Flickr, and \cite{aryafar2014exploring} uses favorited listings on Etsy.

Popularity tends to be predicted using SVM classification or regression \cite{datta2006studying} \cite{khosla2014makes} \cite{chen2014aesthetic} \cite{wang2015automatic}.  Datta et. al. \cite{datta2006studying} uses a two class SVM classifier with a forward selection algorithm to find good feature sets.  By using elastic net to rank feature relevance to aesthetics, and a best first algorithm to find feature sets that minimize the RMSE cross validation error, \cite{wang2015automatic} are able to achieve a 30.1\% improvement compared to \cite{chen2014aesthetic}.  A few have explored other machine learning techniques.  In \cite{ke2006design} a naive Bayes classifier is used, not SVM.  Aryafar et. al \cite{aryafar2014exploring} studied the significance of color in favorited listings on Etsy using logistic regression, perceptron, passive aggressive and margin infused relaxed algorithms.

The features used in popularity prediction model the same qualities professional photographers use such as light, color, rule of thirds, texture, smoothness, blurriness, depth of field, scene composition \cite{ke2006design} \cite{datta2006studying} \cite{chen2014aesthetic} \cite{wang2015automatic}.  Most of these features are unsupervised, but some such as the spacial edge distribution and color distribution features of \cite{ke2006design} require all of the labeled training data.  Some recent work has looked at semantic object features.  \cite{khosla2014makes} used the popular CNN ImageNet to detect the presence of 1000 difference object categories in the image.  The presence/absence of these categories is used as the feature.

With more than 30 million active listings and over 90 million listing images, Etsy provides a unique visually enticing experience
for users. Because images are uploaded by users of the site,
representing the myriad items for sale, these images are composed of different items, presented with various
lighting conditions, scene geometries and background selections. One of
the key components of e-commerce websites is
efficient image search and color filtering methods. Presence of occluded backgrounds and highly
textured material can hinder the accuracy of color detection
algorithms.  In our work, we define popularity as listings that have been favorited, clicked on, or purchased, and we show that unsupervised image popularity features are statistically significant when combined with traditional text meta-data features in predicting popularity.

\section{Features}
\label{sec:features}
  \subsection{Simplicity}
  High quality photos are typically simpler than others.  They often have one subject placed deliberately in the frame.  Sometimes the background is out of focus to emphasize the subject.  Poor quality photographs tend to have cluttered backgrounds and it may be difficult to distinguish the subject of the scene.  We used the four measures of simplicity from \cite{ke2006design}, spatial edge distribution, hue count, contrast and lightness, and blur.

  \subsubsection{Spatial Edge Distribution}
  Spatial edge distribution measures how spread out sharp edges are in the image.  A single subject is expected to have a small distribution while an image with a cluttered background would have a large distribution.  Edges are detected by applying a 3x3 Laplacian filter and taking the absolute value.  The filter is applied to each RGB channel independently and the final image is computed as the mean across all three channels.  The Laplacian image is resized to 100x100 and normalized to sum to 1.  Then, the edges are projected onto the x and y axis independently.  Let $w_x$, and $w_y$ be the width of 98\% of the projected edges respectively.  The image quality feature $f = 1 - {w_x w_y \over 100}$ is the percent of area outside the majority of edges.  Figure \ref{fig:sed} shows the edges detected from two different images and their respective feature value.

\begin{figure*}
  \centering
  \subfigure[]{
    \includegraphics[scale=0.25]{./figures/dress_il_fullxfull_927681771_b525.jpg}
    \hspace{4.1mm}
    \includegraphics[height=0.235\textheight]{./figures/dress_sed.png}
  }
  \subfigure[]{
    \includegraphics[scale=0.26]{./figures/flowers_il_fullxfull_719383783_7d69.jpg}
    \hspace{7mm}
    \includegraphics[scale=0.152]{./figures/flowers_sed.png}
  }
  \caption{
  The Laplacian image for computing spacial edge distribution for two images.  The feature for figure a. is 0.013 and for b. is 0.30.
  }
  \label{fig:sed}
\end{figure*}

  \subsubsection{Hue Count}
  Professional photographs look more colorful and vibrant, but actually tend to have less distinct hues because cluttered scenes contain many heterogeneous objects.  We use a hue count feature by filtering an image in HSV color space such that V is in the range of [0.15, 0.95] and S is greater than 0.2.  A 20 bin histogram is computed on the remaining H values.  Let $m$ be the maximum value of the histogram and let $N = \{i | H(i) > \alpha m\}$, be the set of bins values greater than $\alpha m$.  The quality feature $f = 20 - ||N||$ is 0 when there are a many different hues and larger as the number of distinct hues in the image goes down.  We used $alpha = 0.05$ as in \cite{ke2006design}.

  \subsubsection{Contrast and Lightness}
  Brightness is a well known variable that professional photographers are trained to understand and adjust.  We use the average brightness feature \cite{ke2006design}, \cite{chen2014aesthetic} computed from the L channel of the Lab color space.  Contrast is similar, and is the ratio of maximum and minimum pixel intensities.  We sum the RGB level histograms, and normalize it to sum to 1.  We use the width of the center 98\% mass of the histogram \cite{ke2006design}.

   \subsection{Blur}
  Blurry images are almost always considered to be of poor quality.  We use the blur features of \cite{ke2006design} and \cite{tong2004blur}.  In \cite{ke2006design} blur is modeled as $I_b = G_\sigma * I$ where $I_b$ is the result of convolving a Gaussian filter with an image.  The larger the $\sigma$ the more high frequencies are removed from the image.  Assuming the frequency distribution of all $I$ is approximately the same, then the maximum frequency $||C||$ can be estimated as $C = \{(u, v)\ |\ ||FFT(I_b)|| > \Theta\}$.  The feature is $f = ||C|| \sim 1/\sigma$, after normalizing by the image size.

  In \cite{tong2004blur}, blur estimation is done based on changes in the edge structures.  The blur operation will cause gradual edges to lose sharpness.  Assuming that most images have gradual edges that are sharp enough, the blur is measured as the ratio of gradual edges that have lost their sharpness.

  \subsection{Rule of Thirds}
  The rule of thirds is an important composition technique.  Thirds lines are the horizontal and vertical lines that divide an image into a 3x3 grid of equal sized cells.  The rule of thirds states that subjects placed along these lines are aesthetically more pleasing and more natural than subjects centered in the photograph.  In order to segment the subject of the image from the background, we use the Spectral Residual saliency detection algorithm \cite{hou2007saliency}.  The feature is a 5x5 map where each cell is the average saliency value \cite{mai2011rule}.  Let $w_p$ be the saliency value of the pixel and $A(W_i)$ is the area of the cell, then the value of each cell is
  \begin{equation}
    w_i = {\sum_{p \in W_i} w_p \over A(W_i)} .
  \end{equation}
  To compute the feature, the image is divided into a 5x5 grid with emphasis on the thirds lines; the horizontal and vertical regions centered on the thirds lines are 1/6 of the image size.  Figure \ref{fig:rot} shows the saliecy detection with the 5x5 grid overlay, and the thirds map feature for an image.

\begin{figure*}
  \centering
  \subfigure[]{
    \includegraphics[width=0.3\textwidth]{./figures/frames_il_fullxfull_732324506_py81.jpg}
  }
  \subfigure[]{
    \includegraphics[width=0.3\textwidth]{./figures/frames_saliency.png}
  }
  \subfigure[]{
    \includegraphics[width=0.2\textwidth]{./figures/frames_rot.png}
  }
  \caption{
    Example of Rule of Thirds feature.  Figure b. shows the SR saliency detection, and c. shows the thirds map feature.
  }
  \label{fig:rot}
\end{figure*}

  \subsection{Texture}
  A smooth image may indicate blur or out-of-focus, and the lack of which may indicate poor film, or too high an ISO setting.  In contrast, texture in the scene is an important composition skill of a photographer.  Smoothness may indicate the lack of texture.  Texture and smoothness are some of the most statically correlated features for quality/popularity \cite{wang2015automatic} and \cite{khosla2014makes}.  We use three smoothness/texture features from these.

  A three level wavelet transform is applied to the L channel of the Lab color space.  We only use the bottom level of the pyramid.  The result is squared to indicate power.  Let $b = \{HH, HL, LH\}$ be the bottom level of a wavelet transform, the feature is
  \begin{equation}
    f = {1\over 3MN} \sum_{m=1}^{M}\sum_{n=1}^{N}\sum_{b}w^b(m, n)
  \end{equation}
  where $w$ is the square of the wavelet value.  Because the Laplacian is often used as a pyramid of different scales, another feature
  \begin{equation}
    f = {1\over MN} \sum_{m=1}^{M}\sum_{n=1}^{N}l(m, n)
  \end{equation} is also used.  This time $l$ is the second level from the bottom of a Laplacian pyramid.

  Another texture feature is computed using local binary pattern (LBP).  Then a pyramid of histograms are computed as in \cite{lazebnik2006beyond}.  Figure \ref{fig:tex} shows the similarities of LBP features and the three channels of Daubechies db1 wavelet.

\begin{figure*}
  \centering
  \subfigure[]{
    \includegraphics[width=0.3\textwidth]{./figures/purse_il_fullxfull_528061813_4lgo.jpg}
  }
  \subfigure[]{
    \includegraphics[width=0.3\textwidth]{./figures/purse_lbp.png}
  }
  \subfigure[]{
    \includegraphics[width=0.3\textwidth]{./figures/purse_db10.png}
    \includegraphics[width=0.3\textwidth]{./figures/purse_db11.png}
    \includegraphics[width=0.3\textwidth]{./figures/purse_db12.png}
  }
  \caption{
  Smoothness and texture features.  Figure b. shows Local Binary Pattern (LBP) feature image, and c. shows the 3 channels of the DB1 wavelet transform.
  }
  \label{fig:tex}
\end{figure*}


  \subsection{Depth of Field}
  Depth of field is the distance between between the nearest and farthest objects that appear in sharp focus.  A technique of professional photographers is to use low depth of field to focus on the photographic subject while blurring the background.  We used the feature \cite{datta2006studying} of the ratio of high frequency detail in center regions of the image compared to the entire image.  Let $w$ be the bottom level of a wavelet transform, the feature is
  \begin{equation}
    f ={\sum_{(x,y)}\in M_6\cup M_7\cup M_{10}\cup M_{11} w(x,y) \over \sum_{i=1}^{16}\sum_{(x,y)\in M_i} w(x,y)} ,
  \end{equation}
  where $M_i | 1 \le i \le 16$ are the cells of a 4x4 grid.  The same feature is also reapplied using the Laplacian pyramid $l$ instead of $w$ \cite{wang2015automatic}.  These features only look at the center region of the image.  A third feature \cite{wang2015automatic} looks at the spacial distribution of high frequency details.  Let $l$ be the bottom layer of a Laplacian pyramid and $c_{row}, c_{col}$ are the center of mass, the feature is
  \begin{equation} 
    f = {1 \over MN} \sum_{m=1}^M\sum_{n=1}^N l(m,n)\sqrt{(m-c_{row})^2 + (n-c_{col})^2} .
  \end{equation}
  Figure \ref{fig:lowdof} visualizes how these features are computed for an image.

  \subsection{Experimental}
  Maximally Stable Extremal Regions (MSER) \cite{matas2004robust} can be used to detect text because characters are typically single solid colors with sharp edges that standout from the background \cite{chen2011robust}.  Additionally, texture patterns are also often detected by MSER, like bricks on a wall.  We used the experimental feature the count of the number of MSER regions.  We would like to continue this experiment into other features based on text in images.
 
 \kamelia{fix from here on\\}
\section{Popularity and Quality Features}
\label{sec:experiments}
In this section we present the unique dataset for quantitative evaluation of colors
impact in user behaviour on Etsy. Once an item is listed on Etsy, the
users can favorite a listing which allows them to bring all the items
they like in one place. We first examine the listings dominant colors
to predict if a listings is likely to be favorited or not. Then we
explore the entropy of dominant colors among users favorites to
indicate the color variations among favorited listings.
 Two datasets are used for
classification of favorited listings and color entropy
experiments. The classification dataset consists of $2.73$ million unique
listings that have been created within the last month on Etsy. The
listings images are tagged with the top three dominant colors and
labeled as positive if they have been favorited by a user in that period. 
To collect the entropy dataset, a set of $11235$ active users with more
than $20$ and less than $2000$ favorited listings within the past six
months are selected. The entropy dataset then consists of $2.32$ million unique listings that candidate
users have favorited over the last 6 months on Etsy. These listings
images are also tagged with top three dominant colors. These two
datasets contain more than $5.05$ million listing images and dominant
color tags and are available through Etsy's API\footnote{\url{www.etsy.com/developers}}.

\begin{figure*}
  \centering
  \subfigure[]{
    \includegraphics[width=0.3\textwidth]{./figures/spoons_il_fullxfull_661851396_jppy.jpg}
  }
  \subfigure[]{
    \includegraphics[width=0.304\textwidth]{./figures/spoons_laplacian_low_dof.png}
  }
  \subfigure[]{
    \includegraphics[width=0.3\textwidth]{./figures/spoons_laplacian_low_dof_swd.png}
  }
  \caption{
  Figure b. shows the Low Depth of Field features in the center grid region for the Laplacian image.  Figure c. shows the same image with its center of mass.
  }
  \label{fig:lowdof}
\end{figure*}


\begin{table}
\begin{center}
\begin{tabular}{| l | c | c |}
\hline
Feature & Dimension \\ \hline
'Ke06-qa': spatial edge distribution & 1 \\ \hline
'Ke06-qh': hue count & 1 \\ \hline
'Ke06-qf': blur & 1 \\ \hline
'Ke06-tong': blur tong etal & 1 \\ \hline
'Ke06-qct': contrast & 1 \\ \hline
'Ke06-qb': brightness & 1 \\ \hline
'-mser count': mser count & 1 \\ \hline
'Mai11-thirds map': thirds map & 25 \\ \hline
'Wang15-f1': avg lightness & 1 \\ \hline
'Wang15-f14': wavelet smoothness, & 1 \\ \hline
'Wang15-f18': laplacian smoothness & 1 \\ \hline
'Wang15-f21': wavelet low dof & 1 \\ \hline
'Wang15-f22': laplacian low dof & 1 \\ \hline
'Wang15-f26': laplacian low dof swd & 1 \\ \hline
'Khosla14-texture': texture & 5120 \\ \hline
\hline
\end{tabular}
\end{center}
\caption{Feature Dimensions}
\end{table}

\subsection{Classification}
\label{sec:classification}
\begin{table}[h!]
   \label{tab:classification accuracy}
    \begin{center}
\begin{tabular}{|c||c|c|} 
\hline
Classification method&Average accuracy rate& AUC\\
\hline
 \hline
logistic regression& $0.5512$ & $0.5694$\\ \hline
perceptron&$\mathbf{0.5600}$&$\mathbf{0.5906}$\\ \hline
passive aggressive&$0.5329$& $0.5240$\\ \hline
MIRA&$0.5232$&$0.5240$\\ \hline
 \hline
 \end{tabular}
   \end{center}
\caption{Average classification accuracy rate and AUC are reported
     for favorite listing classification using text and color
     features.}
  \label{tab:classification accuracy}
\end{table}

Once the classification dataset has been tagged with top three
dominant colors, we extract textual information from the
listings. These textual features consist of the tokenized listings
titles unigrams and bigrams and tokenized listings
tags unigrams. We then represent each listing with a feature vector including textual features
and color unigrams. A binary classification is then performed to
predict if the test listings are favorited by
users. We report the average classification accuracy rate and the area
under the curve (AUC) with four different classifiers. Logistic
regression, passive-agressive classifier, perceptron and margin
infused relaxed algorithm (MIRA) are used as the learning models.
Table~\ref{tab:classification accuracy} shows the results
of four rounds of 5-fold classification on this dataset. 
The textual information and color unigrams do not indicate a strong
improvement in favoriting behaviour prediction. It will be interesting
to observe the effects of image quality, memorability, aesthetics and
interestingness for the similar problem on this unique dataset.

\subsection{Entropy Estimation on Selected Users}
\label{sec:entropy}
% \begin{figure}[h!]
%         \centering
%            \includegraphics[scale =0.2] {./figures/chart.jpg}
         
%         \caption{ Number of users in each entropy interval.}
%      \label{fig:chart}
% \end{figure}

In this experiment we measure the entropy of dominant colors
distribution among
$11235$ active users with more
than $20$ and less than $2000$ favorited listings within the past six
months. These users have favorited $2.32$ million unique
listings. The listings images are first tagged with top three dominant
colors and the entropy of color distribution is estimated using the
histogram approach. Figure~\ref{fig:chart} shows the number of users
in each entropy interval. As we can observe in figure~\ref{fig:chart},
most active users have high color distribution entropy in their
favorited listings. There are however, some users with low color
distribution entropy which highlights a strong tendency to favorite
specific colors on Etsy. Figure~\ref{fig:aaa} shows a set of favorites
for a user with the lowest color distribution entropy while
figure~\ref{fig:bbb} illustrates selected favorited listings by
highest color entropy user.

\section{conclusion}
\label{sec:conclusion}
This works represents a initial study on understanding how images,
specifically color-based image features, can be used to represent
items in an e-commerce setting, thereby providing better user
understanding and a better overall shopping experience. To facilitate
this understanding, this work proposed an  empirical method to
estimate the dominant colors of images representing product listings
on Etsy, using object localization. 

We used this dominant colors to filter listings in a conventional text-based e-commerce search, according to user input. Moreover we explored the color distribution among candidate users favorited listings. We also examined the impact of color unigrams on users favoriting behaviour. This work represents the tip of the iceberg of understanding how visual cues influence user action in an e-commerce setting. 

 While color is no doubt important and an influencing factor while shopping, future work involves incorporating a deeper visual understanding of listing images. Image composition, texture and aesthetics all influence the emotional reaction that users have when seeing an item for the first time. Future work seeks to incorporate a richer understanding of images, using this improved representation to better model user preference, and provide a more effective e-commerce experience.

% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{ref}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)

% that's all folks
\end{document}


